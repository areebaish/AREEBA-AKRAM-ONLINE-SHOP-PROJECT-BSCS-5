{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMfe8VW0H+pebxQOCegpx/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/areebaish/AREEBA-AKRAM-ONLINE-SHOP-PROJECT-BSCS-5/blob/main/hybrid_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.23.5\n",
        "!pip install lightfm --force-reinstall\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "collapsed": true,
        "id": "ey4zDLcs2uzV",
        "outputId": "6303d493-d3bf-4e6d-e4b6-1982ec3205dc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.0\n",
            "Uninstalling numpy-1.26.0:\n",
            "  Successfully uninstalled numpy-1.26.0\n",
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "blosc2 3.2.0 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.40.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.21.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "9156029bbc8b409683adf97034935bf7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightfm\n",
            "  Downloading lightfm-1.17.tar.gz (316 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/316.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m102.4/316.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m316.4/316.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy (from lightfm)\n",
            "  Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightfm --force-reinstall\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1L_En6Vj2-Qx",
        "outputId": "5ab13f30-6f91-42b9-8086-ecc3233d3ac3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightfm\n",
            "  Downloading lightfm-1.17.tar.gz (316 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/316.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”\u001b[0m \u001b[32m307.2/316.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m316.4/316.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy (from lightfm)\n",
            "  Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy>=0.17.0 (from lightfm)\n",
            "  Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests (from lightfm)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting scikit-learn (from lightfm)\n",
            "  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->lightfm)\n",
            "  Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->lightfm)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->lightfm)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->lightfm)\n",
            "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn->lightfm)\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn->lightfm)\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: lightfm\n",
            "  Building wheel for lightfm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lightfm: filename=lightfm-1.17-cp311-cp311-linux_x86_64.whl size=831159 sha256=787a7597d61c63b811df90c9e04d806288a3364c6ee67726e1ed23cfb7eb2920\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/0d/8a/0729d2e6e3ca2a898ba55201f905da7db3f838a33df5b3fcdd\n",
            "Successfully built lightfm\n",
            "Installing collected packages: urllib3, threadpoolctl, numpy, joblib, idna, charset-normalizer, certifi, scipy, requests, scikit-learn, lightfm\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: threadpoolctl\n",
            "    Found existing installation: threadpoolctl 3.6.0\n",
            "    Uninstalling threadpoolctl-3.6.0:\n",
            "      Successfully uninstalled threadpoolctl-3.6.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.4.2\n",
            "    Uninstalling joblib-1.4.2:\n",
            "      Successfully uninstalled joblib-1.4.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.1\n",
            "    Uninstalling charset-normalizer-3.4.1:\n",
            "      Successfully uninstalled charset-normalizer-3.4.1\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.1.31\n",
            "    Uninstalling certifi-2025.1.31:\n",
            "      Successfully uninstalled certifi-2025.1.31\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed certifi-2025.1.31 charset-normalizer-3.4.1 idna-3.10 joblib-1.4.2 lightfm-1.17 numpy-2.2.4 requests-2.32.3 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.6.0 urllib3-2.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "charset_normalizer",
                  "joblib"
                ]
              },
              "id": "36882c0535ba40c7b05b96b15c67182c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install flask pandas numpy sklearn lightfm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl1MLDp8ZsaL",
        "outputId": "525f312a-ac8e-4846-f60f-93c1aa8c8d4a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.2.4)\n",
            "Collecting sklearn\n",
            "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31mÃ—\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from lightfm import LightFM\n",
        "from lightfm.data import Dataset\n",
        "from lightfm.evaluation import precision_at_k, auc_score\n",
        "\n",
        "# Load data\n",
        "user_data = pd.read_csv('/content/beauty_user_data.csv')\n",
        "product_data = pd.read_csv('/content/beauty_extended_product_data.csv')\n",
        "interaction_data = pd.read_csv('/content/beauty_extended_interaction_data.csv')\n",
        "\n",
        "# Combine product features for content filtering\n",
        "product_data['Combined_Features'] = (\n",
        "    product_data['Category'] + ' ' + product_data['Type'] + ' ' + product_data['Ingredients'] + ' ' + product_data['Benefits']\n",
        ")\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "product_matrix = vectorizer.fit_transform(product_data['Combined_Features'])\n",
        "\n",
        "# Set up LightFM for collaborative filtering\n",
        "lfm_dataset = Dataset()\n",
        "lfm_dataset.fit(\n",
        "    (row['User ID'] for _, row in interaction_data.iterrows()),\n",
        "    (row['Product ID'] for _, row in product_data.iterrows())\n",
        ")\n",
        "\n",
        "interactions, _ = lfm_dataset.build_interactions(\n",
        "    ((row['User ID'], row['Product ID'], row['Rating']) for _, row in interaction_data.iterrows())\n",
        ")\n",
        "\n",
        "# Train model with improved tuning\n",
        "model = LightFM(loss='warp', learning_rate=0.03, no_components=30)\n",
        "model.fit(interactions, epochs=25, num_threads=4)\n",
        "\n",
        "\n",
        "# âœ… Content-based recommendation function (supports all categories)\n",
        "def content_recommend(category, **kwargs):\n",
        "    # Build user preferences string based on the category\n",
        "    if category == \"skincare\":\n",
        "        user_pref = f\"{category} {kwargs['skin_type']} {kwargs['concern']} {kwargs['frequency']}\"\n",
        "    elif category == \"haircare\":\n",
        "        user_pref = f\"{category} {kwargs['hair_type']} {kwargs['concern']} {kwargs['frequency']}\"\n",
        "    elif category == \"makeup\":\n",
        "        user_pref = f\"{category} {kwargs['skin_tone']} {kwargs['body_part']} {kwargs['finish']}\"\n",
        "    else:\n",
        "        return pd.DataFrame(columns=['Name', 'Category', 'Benefits'])\n",
        "\n",
        "    # Transform user preference into a vector\n",
        "    user_vector = vectorizer.transform([user_pref])\n",
        "\n",
        "    # Filter products by category first\n",
        "    category_products = product_data[product_data['Category'] == category].reset_index(drop=True)\n",
        "\n",
        "    # Handle empty category case\n",
        "    if category_products.empty:\n",
        "        return pd.DataFrame(columns=['Name', 'Category', 'Benefits'])\n",
        "\n",
        "    # Recalculate similarity on filtered category products\n",
        "    category_matrix = vectorizer.transform(category_products['Combined_Features'])\n",
        "    category_similarity = cosine_similarity(user_vector, category_matrix)\n",
        "\n",
        "    # Get top 5 recommendations within this category\n",
        "    recommendations = category_similarity.argsort()[0][-5:][::-1]\n",
        "\n",
        "    return category_products.iloc[recommendations][['Name', 'Category', 'Benefits']]\n",
        "\n",
        "\n",
        "\n",
        "# âœ… Collaborative filtering recommendation function\n",
        "def collaborative_recommend(user_id):\n",
        "    user_idx = lfm_dataset.mapping()[0].get(user_id, 0)\n",
        "    scores = model.predict(user_idx, np.arange(len(product_data)))\n",
        "    top_items = np.argsort(-scores)[:5]\n",
        "    return product_data.iloc[top_items][['Name', 'Category', 'Benefits']]\n",
        "\n",
        "\n",
        "def hybrid_recommend(category, user_id=\"new_user_quiz\", **kwargs):\n",
        "    # Get content-based recommendations\n",
        "    content_rec = content_recommend(category, **kwargs)\n",
        "\n",
        "    # Get collaborative filtering recommendations\n",
        "    collab_rec = collaborative_recommend(user_id)\n",
        "\n",
        "    # Combine both recommendations and remove duplicates\n",
        "    final_recommendations = pd.concat([content_rec, collab_rec]).drop_duplicates().head(10)\n",
        "    return final_recommendations\n",
        "\n",
        "\n",
        "    # Combine and remove duplicates\n",
        "    final_recommendations = pd.concat([content_rec, collab_rec]).drop_duplicates().head(10)\n",
        "    return final_recommendations\n",
        "\n",
        "\n",
        "# ğŸ“Œ Evaluate model performance\n",
        "precision = precision_at_k(model, interactions, k=10).mean()\n",
        "auc = auc_score(model, interactions).mean()\n",
        "print(f'âœ… Precision@10: {precision:.4f}')\n",
        "print(f'âœ… AUC Score: {auc:.4f}')\n",
        "\n",
        "\n",
        "# âœ¨ Example quiz-based recommendations (for different categories)\n",
        "\n",
        "# Skincare Quiz Answers\n",
        "skincare_quiz_answers = {\n",
        "    \"category\": \"skincare\",\n",
        "    \"skin_type\": \"oily\",\n",
        "    \"concern\": \"acne\",\n",
        "    \"frequency\": \"daily\"\n",
        "}\n",
        "\n",
        "# Haircare Quiz Answers\n",
        "haircare_quiz_answers = {\n",
        "    \"category\": \"haircare\",\n",
        "    \"hair_type\": \"straight\",\n",
        "    \"concern\": \"dryness\",\n",
        "    \"frequency\": \"twice a week\"\n",
        "}\n",
        "\n",
        "# Makeup Quiz Answers\n",
        "makeup_quiz_answers = {\n",
        "    \"category\": \"makeup\",\n",
        "    \"skin_tone\": \"medium\",\n",
        "    \"body_part\": \"face\",\n",
        "    \"finish\": \"matte\"\n",
        "}\n",
        "\n",
        "# Get recommendations based on userâ€™s chosen category\n",
        "print(\"\\nğŸ§´ Skincare Recommendations:\\n\", hybrid_recommend(**skincare_quiz_answers))\n",
        "print(\"\\nğŸ’‡ Haircare Recommendations:\\n\", hybrid_recommend(**haircare_quiz_answers))\n",
        "print(\"\\nğŸ’„ Makeup Recommendations:\\n\", hybrid_recommend(**makeup_quiz_answers))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZOJFXWMdMZo",
        "outputId": "7a77708e-018f-4537-ffb4-9caa044f4363"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Precision@10: 0.1480\n",
            "âœ… AUC Score: 0.9988\n",
            "\n",
            "ğŸ§´ Skincare Recommendations:\n",
            "                        Name  Category                       Benefits\n",
            "515           Natural Toner  skincare           Repair, Acne Control\n",
            "787           Premium Serum  skincare    Strengthening, Acne Control\n",
            "1150  Hydrating Moisturizer  skincare      Brightening, Acne Control\n",
            "1492      Natural Face Wash  skincare    Strengthening, Acne Control\n",
            "190          Advanced Toner  skincare      Brightening, Acne Control\n",
            "976    Advanced Moisturizer  skincare    Brightening, Sun Protection\n",
            "1658    Natural Dry Shampoo  haircare   Sun Protection, Acne Control\n",
            "1684    Essential Eyeshadow    makeup              Repair, Hydration\n",
            "2826      Hydrating Mascara    makeup          Hydration, Anti-Frizz\n",
            "1172        Premium Mascara    makeup  Strengthening, Sun Protection\n",
            "\n",
            "ğŸ’‡ Haircare Recommendations:\n",
            "                        Name  Category                       Benefits\n",
            "681        Advanced Shampoo  haircare            Repair, Oil Control\n",
            "1196    Natural Conditioner  haircare            Repair, Oil Control\n",
            "215        Premium Hair Oil  haircare              Hydration, Repair\n",
            "861   Essential Conditioner  haircare         Oil Control, Hydration\n",
            "98      Premium Conditioner  haircare       Strengthening, Hydration\n",
            "976    Advanced Moisturizer  skincare    Brightening, Sun Protection\n",
            "1658    Natural Dry Shampoo  haircare   Sun Protection, Acne Control\n",
            "1684    Essential Eyeshadow    makeup              Repair, Hydration\n",
            "2826      Hydrating Mascara    makeup          Hydration, Anti-Frizz\n",
            "1172        Premium Mascara    makeup  Strengthening, Sun Protection\n",
            "\n",
            "ğŸ’„ Makeup Recommendations:\n",
            "                       Name  Category                       Benefits\n",
            "843       Natural Lipstick    makeup           Matte Finish, Repair\n",
            "925     Natural Foundation    makeup    Matte Finish, Strengthening\n",
            "603        Premium Mascara    makeup    Strengthening, Matte Finish\n",
            "438          Natural Blush    makeup        Matte Finish, Hydration\n",
            "1660    Essential Lipstick    makeup        Hydration, Matte Finish\n",
            "976   Advanced Moisturizer  skincare    Brightening, Sun Protection\n",
            "1658   Natural Dry Shampoo  haircare   Sun Protection, Acne Control\n",
            "1684   Essential Eyeshadow    makeup              Repair, Hydration\n",
            "2826     Hydrating Mascara    makeup          Hydration, Anti-Frizz\n",
            "1172       Premium Mascara    makeup  Strengthening, Sun Protection\n"
          ]
        }
      ]
    }
  ]
}